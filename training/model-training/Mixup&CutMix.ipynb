{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced augmentation (Mixup & CutMix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Mixup and CutMix Functions ---\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "def cutmix_data(x, y, alpha=1.0):\n",
    "    '''Returns cutmixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    shuffled_x = x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "\n",
    "    # Generate cutmix mask\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
    "    x[:, :, bbx1:bbx2, bby1:bby2] = shuffled_x[:, :, bbx1:bbx2, bby1:bby2]\n",
    "    \n",
    "    # Adjust lambda to match pixel ratio\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size()[-1] * x.size()[-2]))\n",
    "    return x, y_a, y_b, lam\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, device, p=0.5, mixup_alpha=1.0, cutmix_alpha=1.0, mixup_ratio=0.5, verbose=0):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    if verbose == 1:\n",
    "        progress_bar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    else:\n",
    "        progress_bar = enumerate(train_loader)\n",
    "    for batch_idx, batch in progress_bar:\n",
    "        data, target = batch\n",
    "\n",
    "        # Move data to device\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # --- Decide Whether to Apply Mix Augmentation ---\n",
    "        if np.random.rand() < p:\n",
    "            # --- Decide Whether to Use Mixup or CutMix ---\n",
    "            if np.random.rand() < (1-mixup_ratio):\n",
    "                # Apply CutMix\n",
    "                data, targets_a, targets_b, lam = cutmix_data(data, target, cutmix_alpha)\n",
    "            else:\n",
    "                # Apply Mixup\n",
    "                data, targets_a, targets_b, lam = mixup_data(data, target, mixup_alpha)\n",
    "\n",
    "            # Forward pass (same for both Mixup and CutMix)\n",
    "            outputs = model(data)\n",
    "            loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate metrics (for mixed targets)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_predictions += target.size(0)\n",
    "            correct_predictions += lam * (predicted == targets_a).sum().item() + (1 - lam) * (predicted == targets_b).sum().item()\n",
    "        else:\n",
    "            # --- Regular Training (No Mix Augmentation) ---\n",
    "            # Reset gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate metrics (for regular targets)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_predictions += target.size(0)\n",
    "            correct_predictions += (predicted == target).sum().item()\n",
    "\n",
    "        if verbose == 1:\n",
    "            # Update progress bar\n",
    "            progress_bar.set_description(f\"Train Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Calculate epoch metrics\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    return epoch_loss, epoch_accuracy"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
